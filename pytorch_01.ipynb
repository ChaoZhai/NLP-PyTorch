{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "**PyTorch Tutorial: 01 Tensors**\n",
    "**Overview**\n",
    "In this series of tutorials, we will introduce some basics of PyTorch. Pay attention that the API's of any library will be subject to changes, therefore it is very important to check the offcial documentation before proceeding.\n",
    "\n",
    "We will cover the following materials in this tutorial.\n",
    "\n",
    "1.Creating tensors.\n",
    "2.Some common manipulations (including broadcast and einsum).\n",
    "**Creating tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.0000],\n",
       "        [0.1000, 0.2000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = torch.tensor([[0.0, 1.0],[0.1, 0.2]])\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor= my_tensor.int().float()\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np_tensor = np.array([[0.1,1.0],[1.0,0.2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy数组转换为tensor numpy默认的浮点数是64位双精度浮点数（GPU 需要单精度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 1.0000],\n",
       "        [1.0000, 0.2000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_np = torch.tensor(np_tensor)\n",
    "tensor_from_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor数组转换为numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. ],\n",
       "       [0.1, 0.2]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_numpy = my_tensor.numpy()\n",
    "to_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor存到GPU中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.0000],\n",
       "        [0.1000, 0.2000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "my_tensor.to(device=device) # See https://pytorch.org/docs/stable/notes/cuda.html for complete examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 1. ],\n",
       "       [0.1, 0.2]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_numpy = my_tensor.numpy()\n",
    "to_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取tensor{[0]}中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_number =  torch.tensor([0])\n",
    "single_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_number.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor中的Autograd，自动求解梯度的功能\n",
    "requires_grad=True 要求计算梯度\n",
    "pow(2).sum() 二次方后求整数\n",
    "backward() 把对应的tensor的梯度都记录下来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 2.0000],\n",
       "        [2.0000, 4.0000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tensor_with_gradient = torch.tensor([[0.1,1.0], [1.0, 2.0]], requires_grad=True)\n",
    "result =tensor_with_gradient.pow(2).sum()\n",
    "result.backward()\n",
    "tensor_with_gradient.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 1.0000],\n",
       "        [1.0000, 2.0000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_with_gradient.detach_() # This will make sure that the Tensor will never need gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1000, 2.0000],\n",
       "        [3.0000, 2.0000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.tensor([[0.1,1.0],[2.0,1.0]])\n",
    "x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 2.0000],\n",
       "        [4.0000, 2.0000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 3.0000],\n",
       "        [4.0000, 4.0000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= torch.tensor([[0.1,2.0],[2.0,3.0]])\n",
    "x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python中的slice  \n",
    "x[:,:] 要所有的位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 1.0000],\n",
       "        [2.0000, 1.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x[1,:]  第一维只要一，第二维要全部"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x[:,1] 第二维的第一个维度，第一维要所有的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squeeze一个维度上只有一位的时候，去掉这个维度  unsqueeze增加一个只有一的维度\n",
    "shape 查看维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1000, 1.0000],\n",
       "          [2.0000, 1.0000]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1000, 1.0000],\n",
       "         [2.0000, 1.0000]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.squeeze(0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算一个线性的层，从矩阵的角度，让W是它的权重，X 是它的输入，W乘以X或者X乘以W  w为10*10 X为10*1 \n",
    "假设X是一个batch进来的，有16个观测，16*10*1  背后复制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two tensors are “broadcastable” if the following rules hold:\n",
    "\n",
    "Each tensor has at least one dimension.（至少有一个维度）\n",
    "\n",
    "When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " x=torch.empty(5,7,3)\n",
    " \n",
    " y=torch.empty(5,7,3)\n",
    " \n",
    "same shapes are always broadcastable (i.e. the above rules always hold)\n",
    "\n",
    "x=torch.empty((0,))\n",
    "\n",
    " y=torch.empty(2,2)\n",
    " \n",
    " x and y are not broadcastable, because x does not have at least 1 dimension\n",
    "\n",
    "can line up trailing dimensions\n",
    "\n",
    " x=torch.empty(5,3,4,1)\n",
    " \n",
    " y=torch.empty(  3,1,1)\n",
    " \n",
    " x and y are broadcastable.\n",
    " \n",
    " 1st trailing dimension: both have size 1\n",
    " \n",
    " 2nd trailing dimension: y has size 1\n",
    " \n",
    " 3rd trailing dimension: x size == y size\n",
    " \n",
    " 4th trailing dimension: y dimension doesn't exist\n",
    " \n",
    "\n",
    "but:\n",
    "\n",
    " x=torch.empty(5,2,4,1)\n",
    " \n",
    " y=torch.empty(  3,1,1)\n",
    " \n",
    " x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000, 3.0000],\n",
       "         [4.0000, 4.0000]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x + y \n",
    "z # This is a case of broadcast, see https://pytorch.org/docs/stable/notes/broadcasting.html for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x ([1, 2, 2]) y([2, 2]) 结果为([1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 3.0000],\n",
       "        [4.0000, 4.0000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z= z.squeeze()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einsum 爱因斯坦发明的一个记载矩阵或者向量乘和加法的一个非常简便的记录方式\n",
    "\n",
    "目的：在这种计算时，没有办法写成标准的内置矩阵运算的时候，可以比较方便做这件事"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: O的ij位 等于X下标为i乘以y的下标为j（笔记中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7042,  2.7819,  0.1232, -1.1915, -1.1433],\n",
       "        [ 1.6281,  2.6578,  0.1177, -1.1383, -1.0922],\n",
       "        [ 0.1894,  0.3092,  0.0137, -0.1324, -0.1271],\n",
       "        [-0.3016, -0.4924, -0.0218,  0.2109,  0.2023],\n",
       "        [ 0.8640,  1.4104,  0.0625, -0.6041, -0.5796]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.randn(5)\n",
    "y= torch.randn(5)\n",
    "torch.einsum('i,j->ij',x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2664,  1.9942, -5.3592],\n",
       "        [ 2.6677, -5.0950, -6.2886]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(3,5,4)\n",
    "l = torch.randn(2,5)\n",
    "r = torch.randn(2,4)\n",
    "torch.einsum('bn,anm,bm->ba', l, A, r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
